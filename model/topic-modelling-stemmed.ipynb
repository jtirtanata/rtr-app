{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic Modelling \n",
    "- [helper functions](#helperFunctions)\n",
    "\n",
    "### [Sentence Tokenizing](#sentTokenizing)\n",
    "\n",
    "### [Cleaning](#cleaning)\n",
    "\n",
    "### [NMF](#nmf)\n",
    "- [5 topics](#nmf-5topics)\n",
    "    - [topic breakdown](#topicBreakdown1)\n",
    "- [4 topics](#nmf-4topics)\n",
    "    - [topic breakdown](#topicBreakdown2)\n",
    "    \n",
    "### [NMF With Nouns](#nmfNouns)\n",
    "- [model 1](#nmfNouns1)\n",
    "    - [topic analysis](#nouns-ta)\n",
    "\n",
    "### [Polarized topics](#polarized)\n",
    "\n",
    "### [Unpolarized topics](#unpolarized)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn import metrics\n",
    "from sklearn.metrics import pairwise_distances\n",
    "from sklearn.metrics import silhouette_score\n",
    "from sklearn.preprocessing import scale\n",
    "from sklearn.datasets import fetch_mldata\n",
    "from sklearn.cluster import KMeans\n",
    "from sklearn.utils import shuffle\n",
    "from nltk.corpus import stopwords\n",
    "from nltk.tokenize import sent_tokenize\n",
    "from pymongo import MongoClient\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "from seaborn import plt\n",
    "import matplotlib.pyplot as mplt\n",
    "%matplotlib inline\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer, CountVectorizer\n",
    "from sklearn.decomposition import NMF, LatentDirichletAllocation\n",
    "import time\n",
    "import nltk\n",
    "from nltk import word_tokenize\n",
    "from nltk.stem.snowball import SnowballStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "client = MongoClient('ec2-34-198-179-91.compute-1.amazonaws.com', 27017)\n",
    "db = client.fletcher\n",
    "dress_col = db.rtr_dresses\n",
    "rev_col = db.rtr_reviews"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "cur = rev_col.find({}, {\"review\":1, \"title\":1,\"_id\":0})\n",
    "rev_df = pd.DataFrame(list(cur))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['review', 'title'], dtype='object')"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rev_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"helperFunctions\"></a>\n",
    "## Helper Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "def print_top_words(model, feature_names, n):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"Topic #%d:\" % topic_idx)\n",
    "        print ([word[0] for word in (sorted(list(zip(feature_names, topic)), key=lambda x: x[1], reverse=True)[:n])])\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def get_tfidf(text, stopwords, max_df=0.90, min_df=0.001, ngram=(2,2), vocab=None):\n",
    "    tfidf_vectorizer = TfidfVectorizer(max_df=max_df, min_df=min_df,\n",
    "                                       ngram_range=ngram,\n",
    "                                       stop_words=sw, vocabulary = vocab)\n",
    "    t0 = time.time()\n",
    "    tfidf = tfidf_vectorizer.fit_transform(text)\n",
    "    return tfidf, tfidf_vectorizer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"sentTokenizing\"></a>\n",
    "## Sentence Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "sentences = rev_df.review.apply(sent_tokenize)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_sent = pd.concat([pd.DataFrame({'review': x, 'index': i}) for i,x in enumerate(sentences)], ignore_index=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stemmer = SnowballStemmer('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_sent.review = df_sent.review.str.lower()\n",
    "df_sent.review = df_sent.review.str.replace(',', ' ')\n",
    "df_sent.review = df_sent.review.str.replace('.', ' ')\n",
    "df_sent.review = df_sent.review.str.replace('!', ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "def stem_sent(text):\n",
    "    return ' '.join([stemmer.stem(word) for word in text.split()])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "stemmed = df_sent.review.apply(stem_sent)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_sent.review = stemmed"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# df_sent.to_csv('../data/stemmed_reviews.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"cleaning\"></a>\n",
    "## Cleaning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"nmf\"></a>\n",
    "## NMF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 5.659s.\n",
      "Extracting tf features for LDA...\n",
      "done in 6.693s.\n"
     ]
    }
   ],
   "source": [
    "sw = stopwords.words('english')\n",
    "tfidf, tfidf_vectorizer, tf, tf_vectorizer = get_tfidf_and_tf(df_sent.review, sw, min_df=0, max_df=0.5, ngram=(1,2))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"nmf-5topics\"></a>\n",
    "### 5 Topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_topics = 5\n",
    "n_top_words = 20\n",
    "t0 = time.time()\n",
    "nmf = NMF(n_components=n_topics, random_state=1,\n",
    "          alpha=.1, l1_ratio=.5).fit(tfidf)\n",
    "print(\"done in %0.3fs.\" % (time.time() - t0))\n",
    "\n",
    "print(\"\\nTopics in NMF model:\")\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0:\n",
      "['love', 'love dress', 'dress', 'absolut love', 'absolut', 'love love', 'overal love', 'overal', 'love wear', 'beauti']\n",
      "Topic #1:\n",
      "['perfect', 'fit', 'fit perfect', 'dress fit', 'dress', 'length', 'great', 'dress perfect', 'fit great', 'length perfect']\n",
      "Topic #2:\n",
      "['compliment', 'mani compliment', 'mani', 'got', 'receiv', 'receiv mani', 'got mani', 'night', 'compliment night', 'compliment dress']\n",
      "Topic #3:\n",
      "['size', 'true size', 'true', 'fit true', 'fit', 'veri', 'comfort', 'dress fit', 'dress', 'veri comfort']\n",
      "Topic #4:\n",
      "['rent', 'would', 'definit', 'dress', 'recommend', 'definit rent', 'would definit', 'rent dress', 'high recommend', 'would rent']\n"
     ]
    }
   ],
   "source": [
    "print_top_words(nmf, tfidf_feature_names, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"topicBreakdown1\"></a>\n",
    "### Topic breakdown\n",
    "1. Topic 0 = Loved the dress\n",
    "2. Topic 1 = Great fit\n",
    "3. Topic 2 = Receive a lot of compliments\n",
    "4. Topic 3 = True to size\n",
    "5. Topic 4 = Would definitely recommend\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"nmfNouns\"></a>\n",
    "## NMF With Nouns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def noun(s):\n",
    "    return ' '.join([word[0] for word in nltk.pos_tag(s) if word[1] == 'NN' or word[1] == 'NNS'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "word_tokens = df_sent.review.apply(nltk.word_tokenize)\n",
    "nouns = word_tokens.apply(noun)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "nouns.to_csv('../data/stemmed_nouns_per_sentence.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_sent['nouns'] = nouns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"nmfNouns1\"></a>\n",
    "### Max df = 0.5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "tfidf, tfidf_vectorizer = get_tfidf(df_sent.nouns, sw, min_df=0, max_df=0.5, ngram=(1, 3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done in 211.225s.\n",
      "\n",
      "Topics in NMF model:\n"
     ]
    }
   ],
   "source": [
    "# Fit the NMF model\n",
    "n_topics = 30\n",
    "t0 = time.time()\n",
    "nmf = NMF(n_components=n_topics, random_state=1, alpha=.1, l1_ratio=.5).fit(tfidf)\n",
    "print(\"done in %0.3fs.\" % (time.time() - t0))\n",
    "\n",
    "print(\"\\nTopics in NMF model:\")\n",
    "tfidf_feature_names = tfidf_vectorizer.get_feature_names()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic #0:\n",
      "['dress', 'dress fit', 'dress size', 'dress comfort', 'rent dress', 'dress dress', 'dress compliment', 'size dress', 'heel dress', 'beauti dress']\n",
      "Topic #1:\n",
      "['size', 'dress size', 'size size', 'order size', 'size fit', 'size dress', 'backup', 'size backup', 'order size size', 'size order']\n",
      "Topic #2:\n",
      "['fit', 'dress fit', 'size fit', 'fit dress', 'fit perfect', 'fit comfort', 'fit well', 'well', 'fit veri', 'fit flatter']\n",
      "Topic #3:\n",
      "['compliment', 'compliment night', 'dress compliment', 'receiv', 'receiv compliment', 'mani compliment', 'mani', 'lot compliment', 'dress compliment night', 'comfort compliment']\n",
      "Topic #4:\n",
      "['heel', 'length heel', 'heel length', 'heel dress', 'floor', 'dress heel', 'heel floor', 'ground', 'order heel', 'size heel']\n",
      "Topic #5:\n",
      "['comfort', 'dress comfort', 'comfort night', 'comfort dress', 'veri comfort', 'comfort easi', 'easi', 'fit comfort', 'size comfort', 'comfort flatter']\n",
      "Topic #6:\n",
      "['order', 'order size', 'order dress', 'size order', 'dress order', 'backup', 'review', 'order backup', 'order medium', 'medium']\n",
      "Topic #7:\n",
      "['night', 'compliment night', 'dress night', 'comfort night', 'night dress', 'ton compliment night', 'dress compliment night', 'lot compliment night', 'danc', 'compliment dress night']\n",
      "Topic #8:\n",
      "['length', 'length heel', 'heel length', 'dress length', 'size length', 'length dress', 'length inch', 'length inch heel', 'fit length', 'inch heel length']\n",
      "Topic #9:\n",
      "['rent', 'rent dress', 'rent runway', 'runway', 'dress rent', 'time rent', 'rent rtr', 'time', 'parti', 'wed']\n",
      "Topic #10:\n",
      "['beauti', 'beauti dress', 'dress beauti', 'fit beauti', 'beauti color', 'compliment beauti', 'comfort beauti', 'beauti comfort', 'color beauti', 'dress fit beauti']\n",
      "Topic #11:\n",
      "['bra', 'bra dress', 'strapless', 'back', 'strapless bra', 'dress bra', 'strap', 'backless', 'bra bra', 'backless bra']\n",
      "Topic #12:\n",
      "['perfect', 'fit perfect', 'dress fit perfect', 'dress fit', 'size fit perfect', 'dress perfect', 'size fit', 'work perfect', 'perfect comfort', 'perfect heel']\n",
      "Topic #13:\n",
      "['lot', 'lot compliment', 'compliment', 'lot compliment dress', 'dress lot', 'lot compliment night', 'dress lot compliment', 'receiv lot', 'receiv lot compliment', 'lot complement']\n",
      "Topic #14:\n",
      "['rtr', 'experi', 'rtr experi', 'thank', 'experi rtr', 'thank rtr', 'dress rtr', 'rtr dress', 'use rtr', 'use']\n",
      "Topic #15:\n",
      "['recommend', 'recommend dress', 'definit', 'definit recommend', 'dress recommend', 'recommend rent', 'recommend event', 'recommend gown', 'recommend size', 'recommend dress event']\n",
      "Topic #16:\n",
      "['glove', 'fit glove', 'dress fit', 'dress fit glove', 'dress glove', 'glove comfort', 'size fit glove', 'dress fit perfect', 'fit glove comfort', 'dress fit size']\n",
      "Topic #17:\n",
      "['veri', 'veri comfort', 'veri flatter', 'fit veri', 'dress veri', 'veri size', 'veri pretti', 'pretti', 'dress fit veri', 'eleg']\n",
      "Topic #18:\n",
      "['bit', 'dress bit', 'arm', 'sequin', 'size bit', 'fit bit', 'bit heel', 'arm bit', 'bit size', 'bust']\n",
      "Topic #19:\n",
      "['ton', 'ton compliment', 'compliment', 'ton compliment night', 'ton compliment dress', 'dress ton', 'dress ton compliment', 'ton complement', 'comfort ton', 'comfort ton compliment']\n",
      "Topic #20:\n",
      "['inch', 'inch heel', 'heel', 'length inch', 'length inch heel', 'inch heel length', 'inch heel dress', 'heel length', 'heel dress', 'dress inch']\n",
      "Topic #21:\n",
      "['littl', 'dress littl', 'littl heel', 'size littl', 'fit littl', 'larg', 'littl larg', 'littl size', 'littl dress', 'bust']\n",
      "Topic #22:\n",
      "['color', 'gold', 'dress color', 'color dress', 'color gold', 'beauti color', 'color beauti', 'pictur', 'person', 'color fit']\n",
      "Topic #23:\n",
      "['pocket', 'dress pocket', 'comfort pocket', 'pocket dress', 'bonus', 'pocket plus', 'plus', 'part', 'pocket bonus', 'phone']\n",
      "Topic #24:\n",
      "['flatter', 'dress flatter', 'veri flatter', 'comfort flatter', 'fit flatter', 'flatter dress', 'flatter comfort', 'flatter fit', 'cut', 'figur']\n",
      "Topic #25:\n",
      "['event', 'dress event', 'tie', 'tie event', 'work', 'work event', 'event dress', 'dress tie', 'day', 'rent event']\n",
      "Topic #26:\n",
      "['love', 'love dress', 'love love', 'love love dress', 'wear', 'dress love', 'love wear', 'wear dress', 'love rtr', 'love wear dress']\n",
      "Topic #27:\n",
      "['compliment dress', 'compliment', 'dress', 'lot compliment dress', 'ton compliment dress', 'compliment dress night', 'dress night', 'receiv compliment dress', 'compliment dress comfort', 'receiv']\n",
      "Topic #28:\n",
      "['fit size', 'fit', 'size', 'dress fit size', 'dress fit', 'fit size comfort', 'fit size length', 'size length', 'size comfort', 'fit size size']\n",
      "Topic #29:\n",
      "['look', 'dress look', 'amaz', 'look dress', 'look amaz', 'pictur', 'fit look', 'amaz dress', 'comfort look', 'size look']\n"
     ]
    }
   ],
   "source": [
    "print_top_words(nmf, tfidf_feature_names, 10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"nouns-ta\"></a>\n",
    "### Topic Analysis\n",
    "- Topic #0: Dress \n",
    "- Topic #1: Fit\n",
    "- Topic #2: Fit\n",
    "- Topic #3: Compliments\n",
    "- Topic #4: Length (+)\n",
    "- Topic #5: Night\n",
    "- Topic #6: Length \n",
    "- Topic #7: Bra (+)\n",
    "- Topic #8: Bit\n",
    "- Topic #9: RTR\n",
    "- Topic #10: Material (+)\n",
    "- Topic #11: Fit like a glove\n",
    "- Topic #12: Wedding (+)\n",
    "- Topic #13: Color (+)\n",
    "- Topic #14: Event (+)\n",
    "- Topic #15: Sequins (+)\n",
    "- Topic #16: Pockets (+)\n",
    "- Topic #17: Back (+)\n",
    "- Topic #18: Heels (+) (kind of related to length)\n",
    "- Topic #19: Perfect\n",
    "- Topic #20: Fit\n",
    "- Topic #21: Stretch (+)\n",
    "- Topic #22: Compliments \n",
    "- Topic #23: Compliments\n",
    "- Topic #24: RTR Experience\n",
    "- Topic #25: Dress size\n",
    "- Topic #26: Way\n",
    "- Topic #27: Bust area (+)\n",
    "- Topic #28: Lots\n",
    "- Topic #29: Reviews\n",
    "\n",
    "The ones with + are significant, and will be used as features of the dress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topic_prob = pd.DataFrame(nmf.transform(tfidf), columns=['topic_{}'.format(i) for i in range(30)])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "good_cols = [1, 4, 7, 10, 12, 13, 14, 15, 16, 17, 18, 21, 27]\n",
    "bad_cols = set(range(30)) - set(good_cols)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for col in bad_cols:\n",
    "    del topic_prob['topic_{}'.format(col)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topic_prob.columns = ['fit', 'length', 'bra', 'material', 'wedding', 'color', 'event', 'sequins', 'pockets', 'back', 'heels', 'stretch', 'bust_area']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I have recognized 3 different group of categories.\n",
    "1. Body type related\n",
    "    - length\n",
    "    - stretch\n",
    "    - bust area\n",
    "2. General \n",
    "    - bra\n",
    "    - material\n",
    "    - wedding \n",
    "    - color \n",
    "    - event\n",
    "    - sequins \n",
    "    - pockets \n",
    "    - back\n",
    "    \n",
    "For the categories that are body type related, it will be scored per body type per dress. For general features, it will be scored per dress.\n",
    "\n",
    "\n",
    "For each category, there's also 3 ways we can \"score\" them\n",
    "1. Polarity (Good/bad)\n",
    "    - Body type related:\n",
    "        - length\n",
    "        - stretch \n",
    "        - bust area\n",
    "    - General\n",
    "        - material \n",
    "        - back \n",
    "        - sequins (itchy or not)\n",
    "        - bra\n",
    "        - color\n",
    "2. Sum (How much it's mentioned)\n",
    "    - sequins\n",
    "    - wedding \n",
    "    - pockets\n",
    "3. Categorical\n",
    "    - bra \n",
    "    - event \n",
    "    - color\n",
    "    \n",
    "\n",
    "\n",
    "    "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linking sentences to dress"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 149,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url_cur = rev_col.find({}, {\"url\":1,\"_id\":0})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "url_list = pd.DataFrame(list(url_cur))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Linking body types to comments"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 223,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_body = pd.read_csv('../data/measurement_data.csv', index_col=0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "<a id=\"polarized\"></a>\n",
    "### Polarized topics\n",
    "\n",
    "<a id=\"polarizedGeneral\"></a>\n",
    "#### General"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 144,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from textblob import TextBlob\n",
    "def calc_polarity(s):\n",
    "    return TextBlob(s).sentiment[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 145,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "polarity = df_sent.review.apply(calc_polarity)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "topic_prob['topic'] = topic_prob.idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 329,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "p_topics = ['bra', 'material', 'color', 'sequins', 'back']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topic_prob = topic_prob.join(polarity)\n",
    "topic_prob = topic_prob.join(df_sent['index'])\n",
    "topic_prob = topic_prob.join(url_list, on='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "topic_prob = topic_prob.rename_axis({'review': 'polarity'}, axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 205,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "polar_general = topic_prob[topic_prob.topic.isin(p_topics)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 206,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "polar_general = pd.DataFrame(polar_general.groupby(['url', 'topic'], as_index=False)['review'].mean())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 215,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "polar_general = polar_general.pivot('url', 'topic', 'review')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 420,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# topic_prob.to_csv('../data/topic_prob.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"polarizedBody\"></a>\n",
    "#### Body Type Specific\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 387,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "bt_topics = ['fit', 'length', 'stretch', 'bust_area']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "polar_bt = topic_prob.join(df_body['kmean_label_2'], on='index')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 406,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "polar_bt = polar_bt.dropna()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 409,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "polar_bt = polar_bt[polar_bt[bt_topics].sum(axis=1) > 0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 411,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/josephinetirtanata/anaconda/lib/python3.5/site-packages/ipykernel/__main__.py:1: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n"
     ]
    }
   ],
   "source": [
    "polar_bt['topic'] = polar_bt[bt_topics].idxmax(axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 412,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "polar_bt = polar_bt.groupby(['url','kmean_label_2', 'topic', 'index'], as_index=False)['polarity'].mean() # make sure 1 entry per user"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 413,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "polar_bt = polar_bt.groupby(['url','kmean_label_2', 'topic'], as_index=False)['polarity'].mean()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 414,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "polar_bt = polar_bt.groupby(['url','kmean_label_2'], as_index=False)['polarity'].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 415,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "polar_bt = polar_bt.pivot('kmean_label_2', 'url', 'polarity')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"unpolarized\"></a>\n",
    "#### Unpolarized topics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "up_topics = ['sequins', 'wedding', 'pockets']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "up_general = topic_prob.groupby('index', as_index=False)[up_topics].sum()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 261,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "up_general = up_general.join(url_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 264,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "up_general = up_general.groupby('url', as_index=False)[up_topics].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<a id=\"combining\"></a>\n",
    "### Combining Everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_general = polar_general.join(up_general.set_index('url'), lsuffix='_polar', rsuffix='_unpolar')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 307,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "df_general = df_general.replace(np.nan, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Saving to CSV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 308,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "df_general.to_csv('../data/dress_features.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 418,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "polar_bt.to_csv('../data/dress_features_bt.csv')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Thoughts \n",
    "- Select which topics are dress related vs people related.\n",
    "- Cluster on similar dresses by the dress features.\n",
    "- Rate people on how much they love the dress. If they love the dress, they will love similar dresses too.\n",
    "- If they input body data, recommend what people with the same body cluster love. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python [conda root]",
   "language": "python",
   "name": "conda-root-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
